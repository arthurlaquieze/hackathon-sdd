{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import wandb\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from dice_score import dice_loss\n",
    "from OSSE_DataLoader import get_data_loaders, get_xarray, normalize_osse\n",
    "from unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "INPUT_IMAGE_HEIGHT = 357\n",
    "INPUT_IMAGE_WIDTH = 717\n",
    "\n",
    "augmentation = transforms.Compose([\n",
    "    transforms.RandomRotation(180),\n",
    "    transforms.RandomCrop((INPUT_IMAGE_HEIGHT//6, INPUT_IMAGE_WIDTH//6)),\n",
    "])\n",
    "    \n",
    "OSSE_train, eddies_train, OSSE_test =  get_xarray()\n",
    "\n",
    "OSSE_train, OSSE_test, *_ = normalize_osse(OSSE_train, OSSE_test)\n",
    "\n",
    "\n",
    "train_dataloader, val_dataloader = get_data_loaders(batch_size, OSSE_train, eddies_train, 0, 0, augmentations=augmentation)\n",
    "\n",
    "data_iter = iter(train_dataloader)\n",
    "\n",
    "features, labels = next(data_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dice_score import multiclass_dice_coeff, dice_coeff\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate(net, dataloader, device, amp):\n",
    "    net.eval()\n",
    "    num_val_batches = len(dataloader)\n",
    "    dice_score = 0\n",
    "\n",
    "    # iterate over the validation set\n",
    "    # with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n",
    "    for (image, mask_true) in tqdm(dataloader, total=num_val_batches, desc='Validation round', unit='batch', leave=False):\n",
    "        # image, mask_true = batch['image'], batch['mask']\n",
    "\n",
    "        # move images and labels to correct device and type\n",
    "        # image = image.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "        image = image.to(device=device, dtype=torch.float32)\n",
    "        mask_true = mask_true.to(device=device, dtype=torch.long)\n",
    "\n",
    "        # predict the mask\n",
    "        mask_pred = net(image)\n",
    "\n",
    "        if net.n_classes == 1:\n",
    "            assert mask_true.min() >= 0 and mask_true.max() <= 1, 'True mask indices should be in [0, 1]'\n",
    "            mask_pred = (F.sigmoid(mask_pred) > 0.5).float()\n",
    "            # compute the Dice score\n",
    "            dice_score += dice_coeff(mask_pred, mask_true, reduce_batch_first=False)\n",
    "        else:\n",
    "            assert mask_true.min() >= 0 and mask_true.max() < net.n_classes, 'True mask indices should be in [0, n_classes['\n",
    "            # convert to one-hot format\n",
    "            # mask_true = F.one_hot(mask_true, net.n_classes).permute(0, 3, 1, 2).float()\n",
    "            # mask_true = F.one_hot(mask_true, net.n_classes).permute(0, 3, 1, 2).float()\n",
    "            mask_true = F.one_hot(mask_true.squeeze(1), net.n_classes).float()\n",
    "            mask_pred = F.one_hot(mask_pred.argmax(dim=1), net.n_classes).permute(0, 3, 1, 2).float()\n",
    "            # compute the Dice score, ignoring background\n",
    "            dice_score += multiclass_dice_coeff(mask_pred[:, 1:], mask_true[:, 1:], reduce_batch_first=False)\n",
    "\n",
    "    net.train()\n",
    "    return dice_score / max(num_val_batches, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "model = UNet(n_channels=4, n_classes=3, bilinear=False)\n",
    "model =model.to(device)\n",
    "# model.to(\"mps\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "# summary(model, input_size=(4, 357//4, 717//4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/hackathon-sdd/lib/python3.9/site-packages/torch/_tensor_str.py:115: UserWarning: The operator 'aten::nonzero' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525849783/work/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8130, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(3.5855, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(5.3351, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(7.1229, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(8.9121, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(10.7066, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(12.5044, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(14.3565, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(16.1693, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(17.9422, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(19.7417, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(21.5601, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(23.3680, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(25.1711, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(26.9763, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(28.7638, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(30.5232, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(32.3091, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(34.0575, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(35.9099, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(37.7343, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(39.5368, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(41.3018, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(43.0522, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(44.8508, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(46.6277, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(48.4310, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(50.2503, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(52.0379, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(53.8116, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(55.5704, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(57.3465, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(59.1317, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(60.9884, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(62.8087, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(64.6370, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(66.4227, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(68.1858, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(69.9843, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(71.7822, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(73.5814, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(75.3807, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(77.2163, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(79.0043, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(80.7969, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(82.5951, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(84.3777, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(86.1744, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(87.9318, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(89.7059, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(91.5427, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(93.3561, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(95.1677, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(96.9382, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(98.7178, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([4, 4, 44, 89])\n",
      "torch.Size([4, 1, 44, 89])\n",
      "tensor(100.5297, device='mps:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 4, 44, 89])\n",
      "torch.Size([3, 1, 44, 89])\n",
      "tensor(101.9873, device='mps:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "loss = 0\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for features, labels in train_dataloader:\n",
    "    print(features.shape)\n",
    "    print(labels.shape)\n",
    "\n",
    "    features = features.to(device)\n",
    "    true_masks = labels.to(device)\n",
    "\n",
    "    masks_pred = model(features)\n",
    "\n",
    "    y_true = torch.squeeze(true_masks, 1).long()\n",
    "\n",
    "    loss += criterion(masks_pred, y_true)\n",
    "    loss += dice_loss(\n",
    "        F.softmax(masks_pred, dim=1).float(),\n",
    "        F.one_hot(y_true, model.n_classes).permute(0, 3, 1, 2).float(),\n",
    "        multiclass=True\n",
    "    )\n",
    "\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (inc): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): Up(\n",
       "    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4): Up(\n",
       "    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outc): OutConv(\n",
       "    (conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, labels = next(data_iter)\n",
    "\n",
    "features = features.to(device, dtype=torch.float32)\n",
    "labels= labels.to(device)\n",
    "\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 89, 179])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.1164e-01, -1.8179e-02, -3.9206e-03,  ..., -8.2241e-01,\n",
       "           -1.8600e-01, -3.6633e-01],\n",
       "          [ 2.0391e-01, -8.0261e-02,  1.2172e-01,  ..., -9.3781e-01,\n",
       "           -5.8848e-01, -1.5908e-01],\n",
       "          [ 1.6411e-01,  6.3528e-02,  2.6253e-02,  ..., -3.0476e-01,\n",
       "            1.6268e-01,  6.7472e-04],\n",
       "          ...,\n",
       "          [ 2.9629e-01, -3.8887e-02,  1.3487e-01,  ..., -2.1646e-01,\n",
       "            5.2838e-01,  5.0821e-01],\n",
       "          [ 1.9403e-01, -4.2702e-01, -1.8601e-01,  ...,  3.6195e-01,\n",
       "            2.9550e-01, -7.9762e-02],\n",
       "          [ 2.2907e-01, -1.2006e-01, -3.0962e-01,  ...,  2.1625e-01,\n",
       "            2.1107e-03,  2.0906e-01]],\n",
       "\n",
       "         [[-1.9044e-01,  2.4912e-01,  5.2261e-02,  ..., -2.1875e-02,\n",
       "            1.5649e-01,  4.6888e-02],\n",
       "          [ 3.9567e-02,  1.0505e-01,  1.7893e-01,  ..., -2.2845e-01,\n",
       "           -1.0090e-01, -4.7845e-02],\n",
       "          [-5.8220e-02,  3.5523e-01,  2.9870e-01,  ..., -1.0247e-02,\n",
       "            2.1321e-03,  7.1031e-02],\n",
       "          ...,\n",
       "          [-5.1183e-02,  3.0027e-01,  1.3569e-01,  ..., -5.6743e-01,\n",
       "            2.4879e-02,  2.1773e-01],\n",
       "          [ 1.2804e-01,  2.0973e-01,  3.1199e-01,  ..., -6.5237e-02,\n",
       "           -2.5414e-01, -4.5984e-01],\n",
       "          [-1.8872e-01, -4.2137e-02, -1.2793e-01,  ..., -2.0642e-01,\n",
       "           -1.2943e-01, -2.8480e-01]],\n",
       "\n",
       "         [[ 2.9068e-01,  6.4364e-02,  1.1753e-01,  ...,  6.3600e-01,\n",
       "            5.9800e-01,  6.1901e-01],\n",
       "          [ 3.5918e-01, -3.5009e-02,  2.1052e-01,  ..., -6.6036e-04,\n",
       "            6.5624e-02, -2.8236e-02],\n",
       "          [ 1.0789e-01, -9.0031e-02, -2.3124e-02,  ...,  1.4522e-01,\n",
       "           -1.1972e-01,  7.0882e-02],\n",
       "          ...,\n",
       "          [ 1.2340e-01, -8.1311e-02,  4.8829e-02,  ...,  7.2217e-03,\n",
       "            4.4968e-01,  9.0637e-01],\n",
       "          [ 2.3073e-01, -2.5113e-01,  1.4937e-01,  ...,  2.1176e-02,\n",
       "            1.0560e-01,  2.2430e-01],\n",
       "          [ 4.3639e-01,  2.3675e-03,  8.0558e-02,  ...,  3.4640e-01,\n",
       "            2.2803e-01,  2.9041e-01]]],\n",
       "\n",
       "\n",
       "        [[[-8.2486e-02, -8.7668e-02, -1.8663e-01,  ..., -2.3861e-01,\n",
       "           -2.7656e-03, -1.4889e-01],\n",
       "          [-1.2272e-02,  1.6311e-01,  4.1798e-01,  ..., -2.3876e-01,\n",
       "            4.6789e-01,  6.6890e-02],\n",
       "          [-3.1081e-02, -1.5424e-01, -9.7654e-02,  ..., -7.3373e-02,\n",
       "            6.0421e-01,  3.2713e-01],\n",
       "          ...,\n",
       "          [ 8.4557e-02, -1.6448e-01, -2.7365e-01,  ...,  6.7855e-01,\n",
       "            1.0501e+00,  2.5300e-01],\n",
       "          [ 1.6914e-01, -7.7819e-02, -1.2787e-01,  ...,  8.3708e-01,\n",
       "            1.0548e+00,  2.7052e-01],\n",
       "          [ 1.2128e-01, -2.2934e-02, -2.5428e-01,  ...,  5.0709e-01,\n",
       "            6.3109e-01,  1.6860e-01]],\n",
       "\n",
       "         [[-3.7485e-01,  5.1532e-02, -1.9612e-01,  ..., -1.3214e-02,\n",
       "            1.2210e-01,  2.0912e-01],\n",
       "          [-7.0573e-02,  1.8260e-01,  1.6929e-02,  ..., -8.8460e-02,\n",
       "            2.2629e-01,  2.2856e-01],\n",
       "          [-3.0732e-01, -1.7654e-01, -2.8153e-01,  ...,  5.8592e-02,\n",
       "           -2.4329e-01,  4.4932e-01],\n",
       "          ...,\n",
       "          [-1.9427e-01, -2.8023e-02, -1.8702e-01,  ..., -3.8979e-01,\n",
       "           -7.6035e-02,  5.7238e-02],\n",
       "          [-4.5160e-02, -1.4110e-01, -1.4086e-01,  ...,  1.9245e-01,\n",
       "            1.2862e-01,  6.9492e-02],\n",
       "          [-3.6242e-01, -2.8571e-01, -3.3887e-01,  ..., -4.3493e-01,\n",
       "           -1.2556e-01, -4.7068e-02]],\n",
       "\n",
       "         [[ 1.8369e-01,  2.5579e-01,  7.5074e-02,  ...,  3.7777e-01,\n",
       "            2.9283e-01, -1.8856e-02],\n",
       "          [ 1.3566e-01, -6.2495e-02, -1.2802e-01,  ...,  2.4850e-01,\n",
       "            4.6359e-01,  8.1998e-02],\n",
       "          [ 1.9875e-01,  7.5055e-02,  6.3325e-03,  ...,  5.0183e-01,\n",
       "            8.2181e-01,  3.1658e-01],\n",
       "          ...,\n",
       "          [ 2.1932e-02, -4.3233e-02,  4.9207e-02,  ...,  1.6759e-01,\n",
       "            2.7572e-01,  2.3310e-01],\n",
       "          [ 1.5998e-01,  6.3890e-02,  1.6545e-01,  ...,  6.5352e-01,\n",
       "            7.7164e-01,  5.1952e-01],\n",
       "          [ 3.0539e-01,  8.2924e-02,  1.4256e-01,  ...,  3.9917e-01,\n",
       "            6.0901e-01,  3.5105e-01]]],\n",
       "\n",
       "\n",
       "        [[[-8.9710e-02, -2.0985e-01, -4.4078e-01,  ...,  4.2612e-02,\n",
       "            1.1128e-01, -1.7401e-01],\n",
       "          [-3.8436e-01,  3.7275e-01, -8.8305e-02,  ...,  1.5423e-01,\n",
       "            2.2579e-01, -1.9556e-01],\n",
       "          [ 6.0751e-02,  3.3960e-01,  2.8106e-01,  ..., -2.8175e-02,\n",
       "            1.1599e-01, -9.9667e-02],\n",
       "          ...,\n",
       "          [ 2.4240e-01, -7.1574e-02,  2.2801e-01,  ..., -2.0025e-01,\n",
       "            7.7692e-02, -2.6888e-01],\n",
       "          [ 2.7920e-01,  8.3883e-02,  1.1434e+00,  ..., -2.7911e-01,\n",
       "            1.4011e-01, -3.6948e-01],\n",
       "          [ 5.2695e-01,  1.9422e-01,  2.1895e-01,  ..., -2.1685e-01,\n",
       "           -6.3643e-02, -2.8758e-01]],\n",
       "\n",
       "         [[ 7.6365e-02,  1.6150e-01, -3.8693e-01,  ..., -1.2286e-02,\n",
       "            6.0415e-02, -5.1735e-02],\n",
       "          [-2.3064e-01,  5.2569e-01, -1.7948e-01,  ...,  1.7464e-01,\n",
       "            2.1547e-01, -4.4940e-02],\n",
       "          [-5.5470e-01,  5.2505e-02,  2.0771e-01,  ...,  2.2059e-01,\n",
       "            2.0978e-01,  7.3754e-02],\n",
       "          ...,\n",
       "          [-2.4399e-01, -4.7389e-01, -2.6678e-01,  ..., -1.2383e-01,\n",
       "            2.0469e-01,  7.1534e-02],\n",
       "          [-6.0942e-01, -3.3794e-01, -6.6990e-02,  ..., -3.3929e-03,\n",
       "           -9.9120e-02,  1.9437e-01],\n",
       "          [-4.1768e-01, -3.6452e-01,  4.6475e-02,  ..., -1.5893e-01,\n",
       "           -2.0299e-01, -1.7327e-01]],\n",
       "\n",
       "         [[ 7.2361e-01,  5.0015e-01,  1.1388e+00,  ...,  7.3738e-02,\n",
       "            1.2425e-01,  2.2303e-01],\n",
       "          [ 6.1782e-01, -3.7712e-01,  7.2038e-01,  ...,  1.3189e-01,\n",
       "            1.2626e-01,  2.3241e-01],\n",
       "          [ 3.6672e-01, -3.0090e-01,  3.0639e-02,  ..., -2.0443e-01,\n",
       "            1.0096e-01,  1.8049e-01],\n",
       "          ...,\n",
       "          [-1.2894e-01,  1.4783e-01,  2.7276e-01,  ..., -7.4111e-02,\n",
       "            1.3966e-01,  2.2803e-01],\n",
       "          [ 4.9935e-01,  6.1498e-02,  1.0312e+00,  ...,  1.7710e-01,\n",
       "            2.8194e-01,  3.1113e-01],\n",
       "          [-8.6314e-02, -2.2236e-02, -1.1980e-03,  ...,  2.8997e-01,\n",
       "            1.0267e-01,  2.1967e-01]]],\n",
       "\n",
       "\n",
       "        [[[-8.2349e-02,  8.9454e-02,  1.9543e-01,  ...,  5.8294e-02,\n",
       "            1.0038e-01, -1.7746e-01],\n",
       "          [-1.0802e-01,  3.6084e-01, -2.2995e-01,  ...,  1.1854e-01,\n",
       "            1.9241e-01, -1.9846e-01],\n",
       "          [ 1.1689e-01,  2.4372e-01,  1.5836e-01,  ...,  4.7395e-02,\n",
       "            1.3389e-01, -1.2896e-01],\n",
       "          ...,\n",
       "          [ 6.4197e-03, -1.3993e-01, -8.3333e-01,  ...,  3.6481e-02,\n",
       "            8.4739e-02, -2.4998e-01],\n",
       "          [ 3.4957e-01, -6.2323e-02, -4.5423e-01,  ..., -1.7889e-01,\n",
       "            4.6574e-02, -3.6957e-01],\n",
       "          [ 3.2875e-01, -8.6295e-02, -4.1609e-02,  ..., -3.0456e-01,\n",
       "           -3.1570e-01, -2.4069e-01]],\n",
       "\n",
       "         [[-1.2465e-01,  8.4069e-02,  3.1173e-03,  ...,  4.1221e-03,\n",
       "            7.6939e-02, -6.1327e-02],\n",
       "          [-1.5396e-01,  3.2305e-01,  3.5292e-01,  ...,  2.2192e-01,\n",
       "            2.2620e-01, -5.5362e-02],\n",
       "          [-9.0270e-02,  1.5339e-02, -2.2680e-01,  ...,  1.9308e-01,\n",
       "            1.5232e-01,  7.7977e-02],\n",
       "          ...,\n",
       "          [-2.2840e-01, -2.3429e-01, -2.2610e-01,  ...,  1.7694e-01,\n",
       "            1.3633e-01,  4.4817e-02],\n",
       "          [-5.6418e-02, -6.9621e-02, -2.2797e-01,  ...,  4.1202e-01,\n",
       "            2.2775e-01,  1.5128e-01],\n",
       "          [-2.2846e-01, -2.8114e-01, -2.8061e-01,  ..., -1.2267e-01,\n",
       "           -1.4497e-01, -1.7431e-01]],\n",
       "\n",
       "         [[ 1.3480e-01, -1.8381e-01, -6.9992e-03,  ...,  8.6636e-02,\n",
       "            1.4631e-01,  2.2083e-01],\n",
       "          [ 2.7176e-01,  1.6655e-01,  2.9763e-01,  ...,  1.4910e-01,\n",
       "            1.6646e-01,  2.4400e-01],\n",
       "          [ 6.4701e-02,  5.4918e-01,  1.9439e-02,  ..., -1.3963e-01,\n",
       "            7.2494e-02,  1.8848e-01],\n",
       "          ...,\n",
       "          [ 3.2409e-01,  3.4776e-01,  2.0111e-01,  ..., -6.2481e-02,\n",
       "            8.2000e-02,  2.3195e-01],\n",
       "          [ 4.4286e-01,  2.5351e-01,  1.5788e-01,  ...,  1.8806e-01,\n",
       "            1.3896e-01,  2.8574e-01],\n",
       "          [ 3.8964e-01,  2.7029e-01,  1.4679e-02,  ...,  7.5979e-02,\n",
       "            8.0587e-02,  2.1236e-01]]]], device='mps:0',\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2ei891xv) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcfd60bee5d4009b29859f6be30fe5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">drawn-deluge-24</strong> at: <a href='https://wandb.ai/arthurlaquieze/U-Net/runs/2ei891xv' target=\"_blank\">https://wandb.ai/arthurlaquieze/U-Net/runs/2ei891xv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230228_120457-2ei891xv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2ei891xv). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e456a6b14a34457bd6b6f5a477c729c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016689087499999998, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/arthur/Dev/Hackathons/hackathon-sdd/wandb/run-20230228_120521-ni0fgyaf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arthurlaquieze/U-Net/runs/ni0fgyaf' target=\"_blank\">summer-dust-25</a></strong> to <a href='https://wandb.ai/arthurlaquieze/U-Net' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arthurlaquieze/U-Net' target=\"_blank\">https://wandb.ai/arthurlaquieze/U-Net</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arthurlaquieze/U-Net/runs/ni0fgyaf' target=\"_blank\">https://wandb.ai/arthurlaquieze/U-Net/runs/ni0fgyaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 127\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39m# print(\"there\")\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[1;32m    125\u001b[0m \u001b[39m# pbar.update(images.shape[0])\u001b[39;00m\n\u001b[1;32m    126\u001b[0m global_step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m    128\u001b[0m \u001b[39m# experiment.log({\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m#     'train loss': loss.item(),\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m#     'step': global_step,\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m#     'epoch': epoch\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m# })\u001b[39;00m\n\u001b[1;32m    133\u001b[0m experiment\u001b[39m.\u001b[39mlog({\n\u001b[1;32m    134\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain loss\u001b[39m\u001b[39m'\u001b[39m: loss\u001b[39m.\u001b[39mitem(),\n\u001b[1;32m    135\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m: global_step,\n\u001b[1;32m    136\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m: epoch\n\u001b[1;32m    137\u001b[0m })\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dir_img = Path('./data/imgs/')\n",
    "dir_mask = Path('./data/masks/')\n",
    "dir_checkpoint = Path('./checkpoints/')\n",
    "\n",
    "epochs = 2000\n",
    "learning_rate = 1e-3\n",
    "val_percent = 0.1\n",
    "save_checkpoint = True\n",
    "img_scale = 1\n",
    "amp = False\n",
    "weight_decay = 1e-8\n",
    "momentum = 0.999\n",
    "gradient_clipping = 1\n",
    "\n",
    "train_loader, val_loader = train_dataloader, val_dataloader\n",
    "\n",
    "\n",
    "n_train = int(len(OSSE_train) * 0.8)\n",
    "n_val = int(len(OSSE_test) * 0.2)\n",
    "\n",
    "# (Initialize logging)\n",
    "experiment = wandb.init(project='U-Net', resume='allow', anonymous='must')\n",
    "experiment.config.update(\n",
    "    dict(epochs=epochs, batch_size=batch_size, learning_rate=learning_rate,\n",
    "            val_percent=val_percent, save_checkpoint=save_checkpoint, img_scale=img_scale, amp=amp)\n",
    ")\n",
    "\n",
    "logging.info(f'''Starting training:\n",
    "    Epochs:          {epochs}\n",
    "    Batch size:      {batch_size}\n",
    "    Learning rate:   {learning_rate}\n",
    "    Training size:   {n_train}\n",
    "    Validation size: {n_val}\n",
    "    Checkpoints:     {save_checkpoint}\n",
    "    Device:          {device.type}\n",
    "    Images scaling:  {img_scale}\n",
    "    Mixed Precision: {amp}\n",
    "''')\n",
    "\n",
    "# 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "optimizer = optim.RMSprop(model.parameters(),\n",
    "                            # lr=learning_rate, weight_decay=weight_decay, momentum=momentum, foreach=True)\n",
    "                            lr=learning_rate, weight_decay=weight_decay, momentum=momentum)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5)  # goal: maximize Dice score\n",
    "# grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "criterion = nn.CrossEntropyLoss() if model.n_classes > 1 else nn.BCEWithLogitsLoss()\n",
    "global_step = 0\n",
    "\n",
    "# print(\"là\")\n",
    "\n",
    "# 5. Begin training\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    # print(\"ici\")\n",
    "    # with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "\n",
    "    for (images, true_masks) in train_loader:\n",
    "        # images, true_masks = batch['image'], batch['mask']\n",
    "\n",
    "        # print(images.shape)\n",
    "        # print(true_masks.shape)\n",
    "\n",
    "        # assert images.shape[1] == model.n_channels, \\\n",
    "        #     f'Network has been defined with {model.n_channels} input channels, ' \\\n",
    "        #     f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n",
    "        #     'the images are loaded correctly.'\n",
    "\n",
    "        # images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "        images = images.to(device)\n",
    "        # images = images.to(device=device, dtype=torch.float32)\n",
    "        # true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "        true_masks = true_masks.to(device)\n",
    "\n",
    "        # print(\"jsuis là fréro\")\n",
    "\n",
    "        # with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n",
    "        masks_pred = model(images)\n",
    "        # print(\"juste ici\")\n",
    "        \n",
    "        # if model.n_classes == 1:\n",
    "        #     loss = criterion(masks_pred.squeeze(1), true_masks.float())\n",
    "        #     loss += dice_loss(F.sigmoid(masks_pred.squeeze(1)), true_masks.float(), multiclass=False)\n",
    "        # else:\n",
    "        #     # loss = criterion(masks_pred, true_masks)\n",
    "        #     # print(masks_pred.shape)\n",
    "        #     # print(true_masks.shape)\n",
    "\n",
    "        #     y_true = torch.squeeze(true_masks, 1)\n",
    "        #     # print(y_true.shape)\n",
    "        #     print(\"là bas\")\n",
    "        #     # loss = criterion(masks_pred, F.one_hot(true_masks, model.n_classes).permute(0, 3, 1, 2).float())\n",
    "        #     loss = criterion(masks_pred, y_true.float())\n",
    "        #     loss += dice_loss(\n",
    "        #         F.softmax(masks_pred, dim=1).float(),\n",
    "        #         # F.one_hot(true_masks, model.n_classes).permute(0, 3, 1, 2).float(),\n",
    "        #         F.one_hot(y_true, model.n_classes).float(),\n",
    "        #         multiclass=True\n",
    "        #     )\n",
    "\n",
    "\n",
    "        y_true = torch.squeeze(true_masks, 1).long()\n",
    "\n",
    "        loss = criterion(masks_pred, y_true)\n",
    "        loss += dice_loss(\n",
    "            F.softmax(masks_pred, dim=1).float(),\n",
    "            F.one_hot(y_true, model.n_classes).permute(0, 3, 1, 2).float(),\n",
    "            multiclass=True\n",
    "        )\n",
    "\n",
    "\n",
    "        # print(\"here\")\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        # grad_scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n",
    "        # grad_scaler.step(optimizer)\n",
    "        # loss.step(optimizer)\n",
    "        # grad_scaler.update()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print(\"there\")\n",
    "\n",
    "        # pbar.update(images.shape[0])\n",
    "        global_step += 1\n",
    "        epoch_loss += loss.item()\n",
    "        # experiment.log({\n",
    "        #     'train loss': loss.item(),\n",
    "        #     'step': global_step,\n",
    "        #     'epoch': epoch\n",
    "        # })\n",
    "        experiment.log({\n",
    "            'train loss': loss.item(),\n",
    "            'step': global_step,\n",
    "            'epoch': epoch\n",
    "        })\n",
    "\n",
    "        # pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "        # Evaluation round\n",
    "        division_step = (n_train // (5 * batch_size))\n",
    "        if division_step > 0:\n",
    "            if global_step % division_step == 0:\n",
    "                histograms = {}\n",
    "                for tag, value in model.named_parameters():\n",
    "                    tag = tag.replace('/', '.')\n",
    "                    if not torch.isinf(value).any():\n",
    "                        histograms['Weights/' + tag] = wandb.Histogram(value.data.cpu())\n",
    "                    if not torch.isinf(value.grad).any():\n",
    "                        histograms['Gradients/' + tag] = wandb.Histogram(value.grad.data.cpu())\n",
    "\n",
    "                val_score = evaluate(model, val_loader, device, amp)\n",
    "                scheduler.step(val_score)\n",
    "\n",
    "                logging.info('Validation Dice score: {}'.format(val_score))\n",
    "                try:\n",
    "                    experiment.log({\n",
    "                    # logging.info({\n",
    "                        'learning rate': optimizer.param_groups[0]['lr'],\n",
    "                        'validation Dice': val_score,\n",
    "                        'images': wandb.Image(images[0].cpu()),\n",
    "                        'masks': {\n",
    "                            'true': wandb.Image(true_masks[0].float().cpu()),\n",
    "                            'pred': wandb.Image(masks_pred.argmax(dim=1)[0].float().cpu()),\n",
    "                        },\n",
    "                        'step': global_step,\n",
    "                        'epoch': epoch,\n",
    "                        **histograms\n",
    "                    })\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    if save_checkpoint:\n",
    "        Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "        state_dict = model.state_dict()\n",
    "        # state_dict['mask_values'] = dataset.mask_values\n",
    "        torch.save(state_dict, str(dir_checkpoint / 'checkpoint_epoch{}.pth'.format(epoch)))\n",
    "        logging.info(f'Checkpoint {epoch} saved!')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon-sdd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f9ceecff076d48798942f8f184cd258593a6625277272087ec6b73d76705584"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
